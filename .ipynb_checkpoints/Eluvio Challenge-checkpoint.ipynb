{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#ignore tensorflow related warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data propocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384239 entries, 0 to 384238\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   time_created  384239 non-null  int64 \n",
      " 1   date_created  384239 non-null  object\n",
      " 2   up_votes      384239 non-null  int64 \n",
      " 3   down_votes    384239 non-null  int64 \n",
      " 4   title         384239 non-null  object\n",
      " 5   over_18       384239 non-null  bool  \n",
      " 6   author        384239 non-null  object\n",
      " 7   category      384239 non-null  object\n",
      "dtypes: bool(1), int64(3), object(4)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# initial work with the data set\n",
    "df = pd.read_csv('Eluvio_DS_Challenge.csv', error_bad_lines=False)\n",
    "\n",
    "# print first few rows of df \n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.842390e+05</td>\n",
       "      <td>384239.000000</td>\n",
       "      <td>384239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.354775e+09</td>\n",
       "      <td>90.322911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.303896e+07</td>\n",
       "      <td>422.632166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.201232e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.312847e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.372113e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.405029e+09</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.437426e+09</td>\n",
       "      <td>21253.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_created       up_votes  down_votes\n",
       "count  3.842390e+05  384239.000000    384239.0\n",
       "mean   1.354775e+09      90.322911         0.0\n",
       "std    6.303896e+07     422.632166         0.0\n",
       "min    1.201232e+09       0.000000         0.0\n",
       "25%    1.312847e+09       1.000000         0.0\n",
       "50%    1.372113e+09       5.000000         0.0\n",
       "75%    1.405029e+09      15.000000         0.0\n",
       "max    1.437426e+09   21253.000000         0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive Statistics for non-categorical variables\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384239\n",
      "384239\n",
      "384239\n"
     ]
    }
   ],
   "source": [
    "#check the number rows of the whole dataset, category columns = worldnews and down_votes = 0\n",
    "\n",
    "print(len(df))\n",
    "print(sum(df['category'] == \"worldnews\"))\n",
    "print(sum(df[\"down_votes\"] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_votes</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   up_votes                                            title\n",
       "0         3                Scores killed in Pakistan clashes\n",
       "1         2                 Japan resumes refuelling mission\n",
       "2         3                  US presses Egypt on Gaza border\n",
       "3         1     Jump-start economy: Give health care to all \n",
       "4         4  Council of Europe bashes EU&UN terror blacklist"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the values in down_votes is all 0s, and all values in category is 'worldnews', we can remove these two features first.\n",
    "# I am trying to create a predictive model between title and up_votes, so we can just keep 'up_votes' and 'title' columns, and remove all other features.\n",
    "df = df.drop(['time_created','date_created','down_votes','over_18','category','author'], 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain stopwords from nltk\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 and token not in stop_words:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called 'clean', then add after remove words of title into 'clean' column\n",
    "df['clean'] = df['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase\n",
    "clean = df.title.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the total words present in the dataset\n",
    "list_of_words = []\n",
    "for i in df.clean:\n",
    "    for j in i:\n",
    "        list_of_words.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scores',\n",
       " 'killed',\n",
       " 'pakistan',\n",
       " 'clashes',\n",
       " 'japan',\n",
       " 'resumes',\n",
       " 'refuelling',\n",
       " 'mission',\n",
       " 'presses',\n",
       " 'egypt',\n",
       " 'gaza',\n",
       " 'border',\n",
       " 'jump',\n",
       " 'start',\n",
       " 'economy',\n",
       " 'health',\n",
       " 'care',\n",
       " 'council',\n",
       " 'europe',\n",
       " 'bashes',\n",
       " 'terror',\n",
       " 'blacklist',\n",
       " 'presto',\n",
       " 'farmer',\n",
       " 'unveils',\n",
       " 'illegal',\n",
       " 'mock',\n",
       " 'tudor',\n",
       " 'castle',\n",
       " 'tried',\n",
       " 'hide',\n",
       " 'bales',\n",
       " 'strikes',\n",
       " 'protests',\n",
       " 'gridlock',\n",
       " 'poland',\n",
       " 'ukraine',\n",
       " 'border',\n",
       " 'mismanagement',\n",
       " 'program',\n",
       " 'nicolas',\n",
       " 'sarkozy',\n",
       " 'threatens',\n",
       " 'ryanair',\n",
       " 'plans',\n",
       " 'missile',\n",
       " 'shields',\n",
       " 'polish',\n",
       " 'town',\n",
       " 'resistance',\n",
       " 'video',\n",
       " 'archbishop',\n",
       " 'canterbury',\n",
       " 'calls',\n",
       " 'punish',\n",
       " 'thoughtless',\n",
       " 'cruel',\n",
       " 'words',\n",
       " 'times',\n",
       " 'online',\n",
       " 'envoy',\n",
       " 'violence',\n",
       " 'kenya',\n",
       " 'ethnic',\n",
       " 'cleansing',\n",
       " 'team',\n",
       " 'building',\n",
       " 'float',\n",
       " 'commemorate',\n",
       " 'holocaust',\n",
       " 'jinero',\n",
       " 'hell',\n",
       " 'idea',\n",
       " 'migrant',\n",
       " 'workers',\n",
       " 'told',\n",
       " 'abandon',\n",
       " 'lunar',\n",
       " 'year',\n",
       " 'holiday',\n",
       " 'plans',\n",
       " 'sarkozy',\n",
       " 'girlfriend',\n",
       " 'ryanair',\n",
       " 'nicolas',\n",
       " 'sarkozy',\n",
       " 'angela',\n",
       " 'merkel',\n",
       " 'confirm',\n",
       " 'opposition',\n",
       " 'turkey',\n",
       " 'membership',\n",
       " 'mass',\n",
       " 'evacuations',\n",
       " 'continue',\n",
       " 'kenya',\n",
       " 'poor',\n",
       " 'haitians',\n",
       " 'resort',\n",
       " 'eating',\n",
       " 'dirt',\n",
       " 'european',\n",
       " 'commission',\n",
       " 'takes',\n",
       " 'greece',\n",
       " 'court',\n",
       " 'environment',\n",
       " 'infringements',\n",
       " 'rambo',\n",
       " 'banned',\n",
       " 'burma',\n",
       " 'possible',\n",
       " 'guantanamo',\n",
       " 'soil',\n",
       " 'video',\n",
       " 'sarkozy',\n",
       " 'says',\n",
       " 'societe',\n",
       " 'generale',\n",
       " 'executives',\n",
       " 'merkel',\n",
       " 'meet',\n",
       " 'leaders',\n",
       " 'turkey',\n",
       " 'united',\n",
       " 'arab',\n",
       " 'emirates',\n",
       " 'spain',\n",
       " 'germany',\n",
       " 'urge',\n",
       " 'tackle',\n",
       " 'economic',\n",
       " 'slowdown',\n",
       " 'prisa',\n",
       " 'lagardere',\n",
       " 'plan',\n",
       " 'control',\n",
       " 'monde',\n",
       " 'worries',\n",
       " 'shrhldrs',\n",
       " 'taliban',\n",
       " 'threatens',\n",
       " 'nato',\n",
       " 'supply',\n",
       " 'lines',\n",
       " 'pakistan',\n",
       " 'video',\n",
       " 'news',\n",
       " 'story',\n",
       " 'germany',\n",
       " 'rejects',\n",
       " 'troop',\n",
       " 'request',\n",
       " 'southern',\n",
       " 'afghanistan',\n",
       " 'secret',\n",
       " 'flights',\n",
       " 'greenland',\n",
       " 'reported',\n",
       " 'denmark',\n",
       " 'pissed',\n",
       " 'investigate',\n",
       " 'commission',\n",
       " 'declines',\n",
       " 'comment',\n",
       " 'microsoft',\n",
       " 'yahoo',\n",
       " 'readies',\n",
       " 'mission',\n",
       " 'independent',\n",
       " 'kosovo',\n",
       " 'hell',\n",
       " 'going',\n",
       " 'eastern',\n",
       " 'cape',\n",
       " 'germany',\n",
       " 'rejects',\n",
       " 'troop',\n",
       " 'request',\n",
       " 'southern',\n",
       " 'afghanistan',\n",
       " 'nicolas',\n",
       " 'sarkozy',\n",
       " 'carla',\n",
       " 'bruni',\n",
       " 'marry',\n",
       " 'erupts',\n",
       " 'chad',\n",
       " 'rebels',\n",
       " 'storm',\n",
       " 'capital',\n",
       " 'overwhelm',\n",
       " 'government',\n",
       " 'forces',\n",
       " 'nero',\n",
       " 'like',\n",
       " 'brown',\n",
       " 'confirms',\n",
       " 'king',\n",
       " 'tony',\n",
       " 'blair',\n",
       " 'calls',\n",
       " 'allies',\n",
       " 'children',\n",
       " 'torched',\n",
       " 'kenya',\n",
       " 'royal',\n",
       " 'bank',\n",
       " 'scotland',\n",
       " 'denies',\n",
       " 'liability',\n",
       " 'stolen',\n",
       " 'escrow',\n",
       " 'monies',\n",
       " 'drug',\n",
       " 'laws',\n",
       " 'work',\n",
       " 'gazprom',\n",
       " 'confirms',\n",
       " 'zubkov',\n",
       " 'running',\n",
       " 'board',\n",
       " 'nicolas',\n",
       " 'sarkozy',\n",
       " 'honeymoons',\n",
       " 'steelworks',\n",
       " 'babacan',\n",
       " 'vows',\n",
       " 'surprise',\n",
       " 'wave',\n",
       " 'reform',\n",
       " 'killed',\n",
       " 'israeli',\n",
       " 'airstrike',\n",
       " 'hamas',\n",
       " 'base',\n",
       " 'kenyan',\n",
       " 'school',\n",
       " 'torched',\n",
       " 'teachers',\n",
       " 'attacked',\n",
       " 'underwater',\n",
       " 'cable',\n",
       " 'damage',\n",
       " 'disrupts',\n",
       " 'internet',\n",
       " 'access',\n",
       " 'middle',\n",
       " 'east',\n",
       " 'asia',\n",
       " 'strip',\n",
       " 'searched',\n",
       " 'meeting',\n",
       " 'starbucks',\n",
       " 'cuts',\n",
       " 'undersea',\n",
       " 'cables',\n",
       " 'middle',\n",
       " 'east',\n",
       " 'total',\n",
       " 'cables',\n",
       " 'sarkozy',\n",
       " 'pair',\n",
       " 'ryanair',\n",
       " 'case',\n",
       " 'russia',\n",
       " 'says',\n",
       " 'iranian',\n",
       " 'missile',\n",
       " 'test',\n",
       " 'week',\n",
       " 'raised',\n",
       " 'suspicions',\n",
       " 'true',\n",
       " 'nuclear',\n",
       " 'ambitions',\n",
       " 'says',\n",
       " 'qaida',\n",
       " 'iraq',\n",
       " 'children',\n",
       " 'iran',\n",
       " 'packet',\n",
       " 'loss',\n",
       " 'website',\n",
       " 'load',\n",
       " 'interesting',\n",
       " 'stories',\n",
       " 'russia',\n",
       " 'steadily',\n",
       " 'unravelling',\n",
       " 'historic',\n",
       " 'arms',\n",
       " 'control',\n",
       " 'treaties',\n",
       " 'ended',\n",
       " 'cold',\n",
       " 'cornerstones',\n",
       " 'european',\n",
       " 'security',\n",
       " 'roman',\n",
       " 'nikolaichik',\n",
       " 'critic',\n",
       " 'vladimir',\n",
       " 'putin',\n",
       " 'sent',\n",
       " 'mental',\n",
       " 'hospital',\n",
       " 'multiple',\n",
       " 'impeachment',\n",
       " 'resolutions',\n",
       " 'pass',\n",
       " 'minnesota',\n",
       " 'democratic',\n",
       " 'party',\n",
       " 'precinct',\n",
       " 'caucuses',\n",
       " 'china',\n",
       " 'israel',\n",
       " 'plans',\n",
       " 'egypt',\n",
       " 'border',\n",
       " 'fence',\n",
       " 'sarkozy',\n",
       " 'says',\n",
       " 'france',\n",
       " 'militarily',\n",
       " 'intervene',\n",
       " 'chad',\n",
       " 'necessary',\n",
       " 'european',\n",
       " 'union',\n",
       " 'leaders',\n",
       " 'hold',\n",
       " 'talks',\n",
       " 'world',\n",
       " 'financial',\n",
       " 'crisis',\n",
       " 'chad',\n",
       " 'rebellion',\n",
       " 'japanese',\n",
       " 'town',\n",
       " 'defies',\n",
       " 'military',\n",
       " 'despite',\n",
       " 'warnings',\n",
       " 'tornadoes',\n",
       " 'kill',\n",
       " 'volcano',\n",
       " 'eruption',\n",
       " 'forces',\n",
       " 'ecuadorians',\n",
       " 'homes',\n",
       " 'qaeda',\n",
       " 'boys',\n",
       " 'training',\n",
       " 'video',\n",
       " 'allow',\n",
       " 'wiretap',\n",
       " 'evidence',\n",
       " 'court',\n",
       " 'pakistan',\n",
       " 'makes',\n",
       " 'important',\n",
       " 'arrests',\n",
       " 'bhutto',\n",
       " 'slaying',\n",
       " 'australia',\n",
       " 'released',\n",
       " 'grisly',\n",
       " 'surveillance',\n",
       " 'pictures',\n",
       " 'slain',\n",
       " 'carcasses',\n",
       " 'whales',\n",
       " 'hauled',\n",
       " 'aboard',\n",
       " 'japanese',\n",
       " 'ship',\n",
       " 'nato',\n",
       " 'good',\n",
       " 'need',\n",
       " 'gruelling',\n",
       " 'years',\n",
       " 'negotiations',\n",
       " 'world',\n",
       " 'trade',\n",
       " 'organisation',\n",
       " 'yesterday',\n",
       " 'gave',\n",
       " 'green',\n",
       " 'light',\n",
       " 'ukraine',\n",
       " 'join',\n",
       " 'member',\n",
       " 'body',\n",
       " 'grifs',\n",
       " 'european',\n",
       " 'commission',\n",
       " 'supports',\n",
       " 'launch',\n",
       " 'global',\n",
       " 'rfid',\n",
       " 'forum',\n",
       " 'standards',\n",
       " 'fukuda',\n",
       " 'gets',\n",
       " 'letter',\n",
       " 'putin',\n",
       " 'indicating',\n",
       " 'resolve',\n",
       " 'island',\n",
       " 'mass',\n",
       " 'arrests',\n",
       " 'anti',\n",
       " 'mafia',\n",
       " 'sweep',\n",
       " 'modern',\n",
       " 'slavery',\n",
       " 'world',\n",
       " 'hypersonic',\n",
       " 'airliner',\n",
       " 'australia',\n",
       " 'hours',\n",
       " 'kidney',\n",
       " 'theif',\n",
       " 'arrested',\n",
       " 'nepal',\n",
       " 'backed',\n",
       " 'russian',\n",
       " 'institutes',\n",
       " 'help',\n",
       " 'iran',\n",
       " 'build',\n",
       " 'reactor',\n",
       " 'serbia',\n",
       " 'plunged',\n",
       " 'crisis',\n",
       " 'rejects',\n",
       " 'deal',\n",
       " 'charges',\n",
       " 'gitmo',\n",
       " 'torture',\n",
       " 'time',\n",
       " 'citizen',\n",
       " 'sharia',\n",
       " 'unavoidable',\n",
       " 'britain',\n",
       " 'leader',\n",
       " 'anglican',\n",
       " 'church',\n",
       " 'internet',\n",
       " 'damaged',\n",
       " 'cables',\n",
       " 'fixed',\n",
       " 'dead',\n",
       " 'satellite',\n",
       " 'earth',\n",
       " 'early',\n",
       " 'march',\n",
       " 'force',\n",
       " 'blast',\n",
       " 'killed',\n",
       " 'bhutto',\n",
       " 'bullet',\n",
       " 'report',\n",
       " 'quasimodo',\n",
       " 'brings',\n",
       " 'music',\n",
       " 'notre',\n",
       " 'dame',\n",
       " 'bells',\n",
       " 'government',\n",
       " 'pays',\n",
       " 'liberian',\n",
       " 'debt',\n",
       " 'debt',\n",
       " 'large',\n",
       " 'scotland',\n",
       " 'yard',\n",
       " 'bomb',\n",
       " 'blast',\n",
       " 'killed',\n",
       " 'bhutto',\n",
       " 'scotland',\n",
       " 'yard',\n",
       " 'bhutto',\n",
       " 'killed',\n",
       " 'bomb',\n",
       " 'blast',\n",
       " 'despite',\n",
       " 'channel',\n",
       " 'obtaining',\n",
       " 'footage',\n",
       " 'assualt',\n",
       " 'iran',\n",
       " 'starts',\n",
       " 'second',\n",
       " 'atomic',\n",
       " 'power',\n",
       " 'plant',\n",
       " 'sons',\n",
       " 'daughters',\n",
       " 'iraq',\n",
       " 'video',\n",
       " 'carl',\n",
       " 'levin',\n",
       " 'surge',\n",
       " 'failed',\n",
       " 'smoking',\n",
       " 'kill',\n",
       " 'billion',\n",
       " 'century',\n",
       " 'babylon',\n",
       " 'mind',\n",
       " 'control',\n",
       " 'military',\n",
       " 'deaths',\n",
       " 'afghanistan',\n",
       " 'island',\n",
       " 'living',\n",
       " 'indian',\n",
       " 'kidney',\n",
       " 'snatching',\n",
       " 'doctor',\n",
       " 'arrested',\n",
       " 'nepal',\n",
       " 'committed',\n",
       " 'crime',\n",
       " 'indian',\n",
       " 'doctor',\n",
       " 'filming',\n",
       " 'patients',\n",
       " 'nude',\n",
       " 'jailed',\n",
       " 'life',\n",
       " 'scotland',\n",
       " 'yard',\n",
       " 'reported',\n",
       " 'blast',\n",
       " 'killed',\n",
       " 'pakistan',\n",
       " 'bhutto',\n",
       " 'iran',\n",
       " 'nulcear',\n",
       " 'ambitions',\n",
       " 'exposed',\n",
       " 'jessica',\n",
       " 'alba',\n",
       " 'shoot',\n",
       " 'nude',\n",
       " 'qaeda',\n",
       " 'leaders',\n",
       " 'operating',\n",
       " 'pakistan',\n",
       " 'white',\n",
       " 'house',\n",
       " 'defends',\n",
       " 'waterboarding',\n",
       " 'bush',\n",
       " 'approval',\n",
       " 'cocaine',\n",
       " 'blow',\n",
       " 'energy',\n",
       " 'drink',\n",
       " 'pure',\n",
       " 'uncut',\n",
       " 'energy',\n",
       " 'japan',\n",
       " 'says',\n",
       " 'russian',\n",
       " 'bomber',\n",
       " 'violated',\n",
       " 'airspace',\n",
       " 'york',\n",
       " 'times',\n",
       " 'assault',\n",
       " 'suit',\n",
       " 'halliburton',\n",
       " 'covered',\n",
       " 'bush',\n",
       " 'lawyers',\n",
       " 'want',\n",
       " 'secret',\n",
       " 'rendition',\n",
       " 'lawsuit',\n",
       " 'dismissed',\n",
       " 'guantanamo',\n",
       " 'detainees',\n",
       " 'said',\n",
       " 'face',\n",
       " 'trial',\n",
       " 'attacks',\n",
       " 'suicide',\n",
       " 'bomber',\n",
       " 'kills',\n",
       " 'bhutto',\n",
       " 'husband',\n",
       " 'opens',\n",
       " 'campaign',\n",
       " 'flee',\n",
       " 'security',\n",
       " 'alert',\n",
       " 'bomb',\n",
       " 'threat',\n",
       " 'sarkozy',\n",
       " 'sues',\n",
       " 'website',\n",
       " 'fake',\n",
       " 'wife',\n",
       " 'blair',\n",
       " 'lead',\n",
       " 'truth',\n",
       " 'european',\n",
       " 'union',\n",
       " 'election',\n",
       " 'observers',\n",
       " 'venezuela',\n",
       " 'balls',\n",
       " 'slams',\n",
       " 'holocaust',\n",
       " 'email',\n",
       " 'hoax',\n",
       " 'news',\n",
       " 'govt',\n",
       " 'moves',\n",
       " 'protect',\n",
       " 'consumer',\n",
       " 'rights',\n",
       " 'sarkozy',\n",
       " 'bush',\n",
       " 'gaddafi',\n",
       " 'deby',\n",
       " 'pedophilia',\n",
       " 'insurgents',\n",
       " 'attack',\n",
       " 'mogadishu',\n",
       " 'chad',\n",
       " 'attempts',\n",
       " 'return',\n",
       " 'normalcy',\n",
       " 'failed',\n",
       " 'coup',\n",
       " 'thousands',\n",
       " 'flee',\n",
       " 'darfur',\n",
       " 'attacks',\n",
       " 'prayers',\n",
       " 'glorified',\n",
       " 'work',\n",
       " 'overlooked',\n",
       " 'aftermath',\n",
       " 'tragedy',\n",
       " 'anonymous',\n",
       " 'scientology',\n",
       " 'protest',\n",
       " 'today',\n",
       " 'assault',\n",
       " 'rough',\n",
       " 'handshake',\n",
       " 'local',\n",
       " 'allies',\n",
       " 'wings',\n",
       " 'mosul',\n",
       " 'fight',\n",
       " 'washingtonpost',\n",
       " 'army',\n",
       " 'buried',\n",
       " 'study',\n",
       " 'faulting',\n",
       " 'iraq',\n",
       " 'planning',\n",
       " 'york',\n",
       " 'times',\n",
       " 'spectacular',\n",
       " 'theft',\n",
       " 'nets',\n",
       " 'million',\n",
       " 'scientology',\n",
       " 'legion',\n",
       " 'doom',\n",
       " 'official',\n",
       " 'chinese',\n",
       " 'face',\n",
       " 'charges',\n",
       " 'security',\n",
       " 'msnbc',\n",
       " 'condoleezza',\n",
       " 'rice',\n",
       " 'visits',\n",
       " 'afghanistan',\n",
       " 'york',\n",
       " 'times',\n",
       " 'eliminated',\n",
       " 'bombing',\n",
       " 'iraq',\n",
       " 'massacring',\n",
       " 'civilians',\n",
       " 'creating',\n",
       " 'terrorists',\n",
       " 'armed',\n",
       " 'robbers',\n",
       " 'steal',\n",
       " 'masterworks',\n",
       " 'zurich',\n",
       " 'russia',\n",
       " 'march',\n",
       " 'return',\n",
       " 'square',\n",
       " 'parades',\n",
       " 'nancy',\n",
       " 'pelosi',\n",
       " 'surge',\n",
       " 'failed',\n",
       " 'french',\n",
       " 'soldiers',\n",
       " 'rebels',\n",
       " 'chad',\n",
       " 'fighting',\n",
       " 'dolly',\n",
       " 'parton',\n",
       " 'donates',\n",
       " 'boobs',\n",
       " 'public',\n",
       " 'wildlife',\n",
       " 'sanctuary',\n",
       " 'time',\n",
       " 'music',\n",
       " 'failed',\n",
       " 'soothe',\n",
       " 'savage',\n",
       " 'beast',\n",
       " 'victim',\n",
       " 'blogosphere',\n",
       " 'halifax',\n",
       " 'daily',\n",
       " 'news',\n",
       " 'shut',\n",
       " 'publish',\n",
       " 'free',\n",
       " 'paper',\n",
       " 'instead',\n",
       " 'russian',\n",
       " 'tupolev',\n",
       " 'flew',\n",
       " 'directly',\n",
       " 'aircraft',\n",
       " 'carrier',\n",
       " 'nimitz',\n",
       " 'twice',\n",
       " 'altitude',\n",
       " 'feet',\n",
       " 'bomber',\n",
       " 'circled',\n",
       " 'miles',\n",
       " 'refugees',\n",
       " 'kenya',\n",
       " 'talking',\n",
       " 'jets',\n",
       " 'scrambled',\n",
       " 'russian',\n",
       " 'bombers',\n",
       " 'flew',\n",
       " 'aircraft',\n",
       " 'carrier',\n",
       " 'navy',\n",
       " 'intercepts',\n",
       " 'russian',\n",
       " 'bombers',\n",
       " 'blackwater',\n",
       " 'shadow',\n",
       " 'army',\n",
       " 'iraq',\n",
       " 'russian',\n",
       " 'bombers',\n",
       " 'intercepted',\n",
       " 'near',\n",
       " 'ship',\n",
       " 'arrests',\n",
       " 'videos',\n",
       " 'fuel',\n",
       " 'free',\n",
       " 'speech',\n",
       " 'debate',\n",
       " 'russia',\n",
       " 'china',\n",
       " 'challenge',\n",
       " 'proposal',\n",
       " 'space',\n",
       " 'weapons',\n",
       " 'russia',\n",
       " 'target',\n",
       " 'missiles',\n",
       " 'ukraine',\n",
       " 'joins',\n",
       " 'nato',\n",
       " 'accepts',\n",
       " 'deployment',\n",
       " 'missile',\n",
       " 'defence',\n",
       " 'shield',\n",
       " 'number',\n",
       " 'armed',\n",
       " 'groups',\n",
       " 'forces',\n",
       " 'child',\n",
       " 'soldiers',\n",
       " 'increases',\n",
       " 'danes',\n",
       " 'uncover',\n",
       " 'plot',\n",
       " 'murder',\n",
       " 'cartoonist',\n",
       " 'cover',\n",
       " 'anonymous',\n",
       " 'scientology',\n",
       " 'protests',\n",
       " 'venezuela',\n",
       " 'minister',\n",
       " 'says',\n",
       " 'country',\n",
       " 'ready',\n",
       " 'europe',\n",
       " 'ready',\n",
       " 'recognize',\n",
       " 'kosovo',\n",
       " 'independence',\n",
       " 'mexican',\n",
       " 'government',\n",
       " 'attack',\n",
       " 'chiapas',\n",
       " 'starts',\n",
       " 'work',\n",
       " 'world',\n",
       " 'zero',\n",
       " 'carbon',\n",
       " 'city',\n",
       " 'plime',\n",
       " 'sailing',\n",
       " 'greece',\n",
       " 'archipelago',\n",
       " 'webb',\n",
       " 'suggests',\n",
       " 'legal',\n",
       " 'action',\n",
       " 'bush',\n",
       " 'iraq',\n",
       " 'caught',\n",
       " 'trying',\n",
       " 'bolivia',\n",
       " 'kevin',\n",
       " 'rudd',\n",
       " 'australia',\n",
       " 'apologises',\n",
       " 'aborigines',\n",
       " 'stolen',\n",
       " 'generation',\n",
       " 'australian',\n",
       " 'government',\n",
       " 'says',\n",
       " 'sorry',\n",
       " 'indigenous',\n",
       " 'australians',\n",
       " 'aborigines',\n",
       " 'open',\n",
       " 'australian',\n",
       " 'parliament',\n",
       " 'australia',\n",
       " 'apologizes',\n",
       " 'aborigines',\n",
       " 'australia',\n",
       " 'apologizes',\n",
       " 'aborigines',\n",
       " 'german',\n",
       " 'court',\n",
       " 'affirms',\n",
       " 'scientology',\n",
       " 'danish',\n",
       " 'papers',\n",
       " 'reprint',\n",
       " 'prophet',\n",
       " 'mohammed',\n",
       " 'cartoon',\n",
       " 'rotten',\n",
       " 'state',\n",
       " 'denmark',\n",
       " 'seconds',\n",
       " 'video',\n",
       " 'good',\n",
       " 'spielberg',\n",
       " 'seeds',\n",
       " 'class',\n",
       " 'sprout',\n",
       " 'kenya',\n",
       " 'crisis',\n",
       " 'suspects',\n",
       " 'formally',\n",
       " 'charged',\n",
       " 'secret',\n",
       " 'trials',\n",
       " 'bolivia',\n",
       " 'declares',\n",
       " 'flood',\n",
       " 'emergency',\n",
       " 'hezbollah',\n",
       " 'commander',\n",
       " 'terrorist',\n",
       " 'list',\n",
       " 'killed',\n",
       " 'indians',\n",
       " 'need',\n",
       " 'passports',\n",
       " 'travel',\n",
       " 'states',\n",
       " 'india',\n",
       " 'iran',\n",
       " 'generation',\n",
       " 'advanced',\n",
       " 'centrifuges',\n",
       " 'begun',\n",
       " 'processing',\n",
       " 'small',\n",
       " 'quantities',\n",
       " 'fissile',\n",
       " 'core',\n",
       " 'nuclear',\n",
       " 'warheads',\n",
       " 'danish',\n",
       " 'papers',\n",
       " 'reprint',\n",
       " 'muhammad',\n",
       " 'cartoon',\n",
       " 'unambiguously',\n",
       " 'freedom',\n",
       " 'country',\n",
       " 'went',\n",
       " 'worries',\n",
       " 'energy',\n",
       " 'warping',\n",
       " 'diplomacy',\n",
       " 'surf',\n",
       " 'paitent',\n",
       " 'uses',\n",
       " 'meat',\n",
       " 'cleaver',\n",
       " 'hack',\n",
       " 'pychologist',\n",
       " 'kathryn',\n",
       " 'faughey',\n",
       " 'scalia',\n",
       " 'says',\n",
       " 'sees',\n",
       " 'role',\n",
       " 'physical',\n",
       " 'interrogations',\n",
       " 'york',\n",
       " 'times',\n",
       " 'mccain',\n",
       " 'standing',\n",
       " 'standing',\n",
       " 'torture',\n",
       " 'surge',\n",
       " 'pause',\n",
       " 'deludes',\n",
       " 'thousands',\n",
       " 'prisoners',\n",
       " 'overwhelm',\n",
       " 'iraqi',\n",
       " 'york',\n",
       " 'times',\n",
       " 'france',\n",
       " 'sarkozy',\n",
       " 'calls',\n",
       " 'world',\n",
       " 'mission',\n",
       " 'mars',\n",
       " 'ahmadinejad',\n",
       " 'visit',\n",
       " 'iraq',\n",
       " 'word',\n",
       " 'hugo',\n",
       " 'chavez',\n",
       " 'fungible',\n",
       " 'iraq',\n",
       " 'trillion',\n",
       " 'dollar',\n",
       " 'rejects',\n",
       " 'russian',\n",
       " 'space',\n",
       " 'treaty',\n",
       " 'billy',\n",
       " 'graham',\n",
       " 'alert',\n",
       " 'brain',\n",
       " 'surgery',\n",
       " 'doctor',\n",
       " 'says',\n",
       " 'indystar',\n",
       " 'bush',\n",
       " 'veto',\n",
       " 'torture',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the all words in the dataset\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3363936"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the len of list_of_words\n",
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the words into a string and add it to new column\n",
    "df['clean_joined'] = df['clean'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71220"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the total number of unique words\n",
    "total_words = len(list(set(list_of_words)))\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384239, 213)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert texts of title to matrix of token counts with Countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "tfidf = CountVectorizer(\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,)\n",
    "docs = df.clean_joined\n",
    "tfidf.fit(docs)\n",
    "\n",
    "vector_1 = tfidf.transform(docs)\n",
    "vector_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    309360\n",
       "0     74879\n",
       "Name: new, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# if there is up vote, it will be 1. otherwise it will be 0. create a another column called 'new' and add the value to 'new' column.\n",
    "df['new'] = np.where(df['up_votes']!= 0, 1, 0)\n",
    "# count the value in 'new' column\n",
    "df['new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1878c9edd08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # plot the number of 0 an 1 in 'new'\n",
    "plot.figure(figsize = (8,8))\n",
    "sns.countplot(y = 'new',data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test,\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector_1, y, test_size = 0.2, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=1.0, penalty='l1', solver = 'liblinear')\n",
    "LR.fit(X_train,y_train)\n",
    "\n",
    "# Compute RMSE on training / test\n",
    "y_pred_train_LR = LR.predict(X_train)\n",
    "y_pred_test_LR = LR.predict(X_test)\n",
    "\n",
    "\n",
    "# Construct a vector of errors for train and test data sets\n",
    "LR_err_train = abs(y_pred_train_LR - y_train)\n",
    "LR_err_test = abs(y_pred_test_LR - y_test)\n",
    "\n",
    "\n",
    "# Compute MSE for Train set, Test set\n",
    "mse_LR_train = mean_squared_error(y_train, y_pred_train_LR)\n",
    "mse_LR_test = mean_squared_error(y_test, y_pred_test_LR)\n",
    "\n",
    "\n",
    "# Compute RMSE for Train set, Test set\n",
    "rmse_LR_train = sqrt(abs(mse_LR_train))\n",
    "rmse_LR_test = sqrt(abs(mse_LR_test))\n",
    "\n",
    "\n",
    "# print(\"MSE - Lin Reg - train:    %.4f\" % mse_lr_train)\n",
    "# print(\"MSE - Lin Reg - test:     %.4f\" % mse_lr_test)\n",
    "# print(\"MSE - Lin Reg - all :     %.4f\" % mse_lr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Summary for Logistic Regression\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "RMSE - Logistic Reg - train:      0.4415\n",
      "RMSE - Logistic Reg - test:       0.4407\n",
      "\n",
      "ACCURACY Summary\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "Accuracy: Logistic Reg - train:    81 %\n",
      "Accuracy: Logistic Reg - test:     81 %\n",
      "\n",
      "RMSE Summary for 10-cv\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "RMSE - 10cv - train:          0.4416\n",
      "RMSE - 10cv - test:           0.4408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "\n",
    "# Cross Validation Regression MSE\n",
    "\n",
    "seed = 7\n",
    "kf = KFold(n_splits=10, random_state=seed)\n",
    "LR_kf = LogisticRegression(C=1.0, penalty='l1', solver = 'liblinear')\n",
    "scoring_kf = 'neg_mean_squared_error'\n",
    "results_kf_train = cross_val_score(LR_kf, X_train, y_train, cv=kf, scoring=scoring_kf)\n",
    "results_kf_test  = cross_val_score(LR_kf, X_test, y_test, cv=kf, scoring=scoring_kf)\n",
    "\n",
    "# print(\"MSE: \", (results_kf.mean(), results_kf.std()))\n",
    "# print(\"MSE: \", (results_kf.mean()))\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_kf_train = sqrt(abs(results_kf_train.mean()))\n",
    "rmse_kf_test  = sqrt(abs(results_kf_test.mean()))\n",
    "\n",
    "\n",
    "# Compute Accuracy\n",
    "acc_LR_train = LR.score(X_train, y_train)\n",
    "acc_LR_test  = LR.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Print Accuracy & RMSE\n",
    "print('\\nRMSE Summary for Logistic Regression')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(\"RMSE - Logistic Reg - train:      %.4f\" % rmse_LR_train)\n",
    "print(\"RMSE - Logistic Reg - test:       %.4f\" % rmse_LR_test)\n",
    "\n",
    "\n",
    "print('\\nACCURACY Summary')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print('Accuracy: Logistic Reg - train:   ', round(100 * acc_LR_train), '%')\n",
    "print('Accuracy: Logistic Reg - test:    ', round(100 * acc_LR_test), '%')\n",
    "\n",
    "\n",
    "print('\\nRMSE Summary for 10-cv')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(\"RMSE - 10cv - train:          %.4f\" % rmse_kf_train)\n",
    "print(\"RMSE - 10cv - test:           %.4f\" % rmse_kf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057984592962731"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_LR = LR.score(X_test, y_test)\n",
    "acc_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.00      0.00     14927\n",
      "           1       0.81      1.00      0.89     61921\n",
      "\n",
      "    accuracy                           0.81     76848\n",
      "   macro avg       0.80      0.50      0.45     76848\n",
      "weighted avg       0.80      0.81      0.72     76848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = LR.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomailNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Compute RMSE on training / test \n",
    "y_pred_train_clf = clf.predict(X_train)\n",
    "y_pred_test_clf = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Construct a vector of errors for train and test data sets\n",
    "clf_err_train = abs(y_pred_train_clf - y_train)\n",
    "clf_err_test = abs(y_pred_test_clf - y_test)\n",
    "\n",
    "\n",
    "# Compute MSE for Train set, Test set\n",
    "mse_clf_train = mean_squared_error(y_train, y_pred_train_clf)\n",
    "mse_clf_test = mean_squared_error(y_test, y_pred_test_clf)\n",
    "\n",
    "\n",
    "# Compute RMSE for Train set, Test set\n",
    "rmse_clf_train = sqrt(abs(mse_clf_train))\n",
    "rmse_clf_test = sqrt(abs(mse_clf_test))\n",
    "\n",
    "\n",
    "# print(\"MSE - Lin Reg - train:    %.4f\" % mse_lr_train)\n",
    "# print(\"MSE - Lin Reg - test:     %.4f\" % mse_lr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Summary for MultinomailNB\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "RMSE - MultinomailNB - train:      0.4416\n",
      "RMSE - MultinomailNB - test:       0.4408\n",
      "\n",
      "ACCURACY Summary\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "Accuracy: MultinomailNB - train:    80 %\n",
      "Accuracy: MultinomailNB - test:     81 %\n",
      "\n",
      "RMSE Summary for 10-cv\n",
      "- - - - - - - - - - - - - - - - - - - -\n",
      "RMSE - 10cv - train:          0.4417\n",
      "RMSE - 10cv - test:           0.4410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "# Cross Validation Regression MSE\n",
    "\n",
    "seed = 7\n",
    "kf = KFold(n_splits=10, random_state=seed)\n",
    "clf_kf =  MultinomialNB()\n",
    "scoring_kf = 'neg_mean_squared_error'\n",
    "results_kf_train = cross_val_score(clf_kf, X_train, y_train, cv=kf, scoring=scoring_kf)\n",
    "results_kf_test  = cross_val_score(clf_kf, X_test, y_test, cv=kf, scoring=scoring_kf)\n",
    "\n",
    "# print(\"MSE: \", (results_kf.mean(), results_kf.std()))\n",
    "# print(\"MSE: \", (results_kf.mean()))\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_kf_train = sqrt(abs(results_kf_train.mean()))\n",
    "rmse_kf_test  = sqrt(abs(results_kf_test.mean()))\n",
    "\n",
    "\n",
    "# Compute Accuracy\n",
    "acc_clf_train = clf.score(X_train, y_train)\n",
    "acc_clf_test  = clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Print Accuracy & RMSE\n",
    "print('\\nRMSE Summary for MultinomailNB')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(\"RMSE - MultinomailNB - train:      %.4f\" % rmse_clf_train)\n",
    "print(\"RMSE - MultinomailNB - test:       %.4f\" % rmse_clf_test)\n",
    "\n",
    "\n",
    "print('\\nACCURACY Summary')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print('Accuracy: MultinomailNB - train:   ', round(100 * acc_clf_train), '%')\n",
    "print('Accuracy: MultinomailNB - test:    ', round(100 * acc_clf_test), '%')\n",
    "\n",
    "\n",
    "print('\\nRMSE Summary for 10-cv')\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(\"RMSE - 10cv - train:          %.4f\" % rmse_kf_train)\n",
    "print(\"RMSE - 10cv - test:           %.4f\" % rmse_kf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057203830938996"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_clf = clf.score(X_test, y_test)\n",
    "acc_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.00      0.00     14927\n",
      "           1       0.81      1.00      0.89     61921\n",
      "\n",
      "    accuracy                           0.81     76848\n",
      "   macro avg       0.63      0.50      0.45     76848\n",
      "weighted avg       0.74      0.81      0.72     76848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045102019571101"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100,max_features = 1 ,min_impurity_split = 0.01)\n",
    "rf.fit(X_train,y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "\n",
    "acc_rf = rf.score(X_test, y_test)\n",
    "acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.02      0.04     14927\n",
      "           1       0.81      0.99      0.89     61921\n",
      "\n",
      "    accuracy                           0.80     76848\n",
      "   macro avg       0.62      0.51      0.46     76848\n",
      "weighted avg       0.73      0.80      0.73     76848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         18232320  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,348,737\n",
      "Trainable params: 19,348,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "model = Sequential() \n",
    "\n",
    "# embeddidng layer\n",
    "#model.add(Embedding(total_words, output_dim = 128))\n",
    "model.add(Embedding(total_words, output_dim = 256))\n",
    "\n",
    "\n",
    "# Bi-Directional RNN and LSTM\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(1,activation= 'sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307391,)\n",
      "(307391, 213)\n"
     ]
    }
   ],
   "source": [
    "# conver y_train data to np array\n",
    "y_train = np.asarray(y_train)\n",
    "# conver X_train data to np arrary\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "# Check if the shape of X_train and y_train are same\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4323/4323 [==============================] - 11399s 3s/step - loss: 0.1559 - acc: 0.8053 - val_loss: 0.1518 - val_acc: 0.8094\n",
      "Epoch 2/2\n",
      "4323/4323 [==============================] - 15177s 4s/step - loss: 0.1551 - acc: 0.8047 - val_loss: 0.1520 - val_acc: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1878d04ef08>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size = 64, validation_split = 0.1, epochs = 2)\n",
    "# print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80200505],\n",
       "       [0.80798984],\n",
       "       [0.756066  ],\n",
       "       ...,\n",
       "       [0.7838036 ],\n",
       "       [0.8051793 ],\n",
       "       [0.7831292 ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the predicted value is >0.5, it is 1 else it is 0\n",
    "prediction = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i].item() > 0.5:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy :  0.805772433895482\n"
     ]
    }
   ],
   "source": [
    "# getting the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_rnn = accuracy_score(y_test, prediction)\n",
    "print(\"Model Accuracy : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL ACCURACY REPORT SUMMARY\n",
      "\n",
      "MODEL\t\t\t\t\t ENTIRE SET(%)\t \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "Logistic Regression\t\t\t 0.80580\t\t \n",
      "MultinomailNB\t\t\t\t 0.80572\t\t\t \n",
      "Random Forest\t\t\t\t 0.80451\t\t \n",
      "RNN- LSTM model\t\t\t\t 0.80577\t\t \n"
     ]
    }
   ],
   "source": [
    "###### MODEL ACCURACY REPORT SUMMARY\n",
    "M1_lr=\"Logistic Regression\"\n",
    "M2_clf=\"MultinomailNB\"\n",
    "M3_rf=\"Random Forest\"\n",
    "M4_rnn=\"RNN- LSTM model\"\n",
    "\n",
    "\n",
    "print('\\nMODEL ACCURACY REPORT SUMMARY')\n",
    "print('{}\\t\\t\\t\\t\\t {}\\t '.format('\\nMODEL','ENTIRE SET(%)'))\n",
    "print('- - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "print('{}\\t\\t\\t {:.5f}\\t\\t '.format(M1_lr,acc_LR))\n",
    "print('{}\\t\\t\\t\\t {:.5f}\\t\\t\\t '.format(M2_clf,acc_clf))\n",
    "print('{}\\t\\t\\t\\t {:.5f}\\t\\t '.format(M3_rf,acc_rf))\n",
    "print('{}\\t\\t\\t\\t {:.5f}\\t\\t '.format(M4_rnn,acc_rnn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
